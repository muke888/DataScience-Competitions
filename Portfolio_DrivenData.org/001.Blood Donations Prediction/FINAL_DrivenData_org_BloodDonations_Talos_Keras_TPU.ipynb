{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL_DrivenData.org BloodDonations - Talos Keras TPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3O9Piu57EEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "cwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkkaGrXxUVTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqGu4YkKxPKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''#!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil -q\n",
        "!pip install psutil -q\n",
        "!pip install humanize -q\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()'''\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffKz59Dj7T_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Keras save folder\n",
        "\n",
        "#os.chdir(r'C:\\Users\\Murat Eliby\\Desktop\\wd')\n",
        "if not os.path.exists('/content/keras'):\n",
        "    os.makedirs('/content/keras')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtTq-piE7UCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Empty keras folder\n",
        "\n",
        "import os, shutil\n",
        "folder = '/content/keras'\n",
        "for the_file in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, the_file)\n",
        "    try:\n",
        "        if os.path.isfile(file_path):\n",
        "            os.unlink(file_path)\n",
        "        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoIzsT-S7UEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Blood Donations Prediction 23.01.2019\n",
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Importing the dataset\n",
        "!curl https://raw.githubusercontent.com/muke888/Portfolio_DrivenData.org/master/001.Blood%20Donations%20Prediction/BloodDonations_TrainData.csv -o TrainData.csv\n",
        "!curl https://raw.githubusercontent.com/muke888/Portfolio_DrivenData.org/master/001.Blood%20Donations%20Prediction/BloodDonations_TestData.csv  -o TestData.csv \n",
        "datatrain = pd.read_csv('TrainData.csv')\n",
        "datatest = pd.read_csv('TestData.csv')\n",
        "datatrain.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6mrZR0L7UG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datatrain.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vze83Lvq7UJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datatrain_x = datatrain.drop(['Made Donation in March 2007','Total Volume Donated (c.c.)'],\t axis=1)\n",
        "datatest = datatest.drop('Total Volume Donated (c.c.)', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wFwfgPq7UYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_data = pd.concat([datatrain_x, datatest], ignore_index=True)\n",
        "combined_data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGnxxG3X7UXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler_X = combined_data.iloc[:,1:].values\n",
        "scaler_X[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDospnJm7UWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Scaling - StandardScaler\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "sc.fit(scaler_X)\n",
        "\n",
        "\n",
        "X = datatrain_x.iloc[:,1:].values\n",
        "y = datatrain.iloc[:, 5].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAA6eYVA7lWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)#, stratify=y)\n",
        "\n",
        "#scale_transform based on all data\n",
        "X_train = sc.transform(X_train)\n",
        "X_test = sc.transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of2-R8uM7lqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "print(x.shape,y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMZA_RTk-KA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q talos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dak4guHGCzfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input dimension\n",
        "X_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQOQg9xqGpz0",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import talos as ta\n",
        "\n",
        "from talos.model import lr_normalizer\n",
        "from talos.model.early_stopper import early_stopper\n",
        "\n",
        "LeakyReLU = tf.keras.layers.LeakyReLU(alpha=0.3)\n",
        "ELU = tf.keras.layers.ELU(alpha=1.0)\n",
        "ReLU = tf.keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\n",
        "\n",
        "para = {\n",
        "    'dense1_neuron': [2, 3],\n",
        "    'dense2_neuron': [2, 3],\n",
        "    'dense3_neuron': [2, 3],\n",
        "    'activation':[LeakyReLU, ELU],\n",
        "    'batch_size': [27, 16, 8],\n",
        "    'weight_regulizer':[None],\n",
        "    'dropout': [0, 0.1],\n",
        "    'epochs': [500],\n",
        "    #'optimizer': [Adam], #Nadam\n",
        "    'kernel_initializer': ['glorot_uniform'],\n",
        "    'last_activation': ['sigmoid']\n",
        "}\n",
        "\n",
        "\n",
        "def biclass_fn_gpu1(X_train, y_train, X_test, y_test, params):\n",
        "  \n",
        "    tf.keras.backend.clear_session()\n",
        "    #dropout = float(params['dropout'])\n",
        "    #dense1_neuron = int(params['dense1_neuron'])\n",
        "    \n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(units=params['dense1_neuron'],input_dim=3,kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(params['activation'])\n",
        "    model.add(tf.keras.layers.Dropout(params['dropout']))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(units=params['dense2_neuron'],kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(params['activation'])\n",
        "    model.add(tf.keras.layers.Dropout(params['dropout']))    \n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(units=params['dense3_neuron'],kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(params['activation'])\n",
        "    model.add(tf.keras.layers.Dropout(params['dropout'])) \n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(units=1,kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(\"sigmoid\"))\n",
        "    \n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=tf.train.AdamOptimizer(learning_rate=1e-3, ),\n",
        "        loss=tf.keras.losses.binary_crossentropy,\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    out = model.fit(\n",
        "        X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'],\n",
        "        verbose=0,\n",
        "        validation_data=[X_test, y_test] #,callbacks=[early_stopper(params['epochs'], mode='moderate')]\n",
        "    )\n",
        "    \n",
        "    return out, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MC6Udcn-KOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import talos as ta\n",
        "import os\n",
        "\n",
        "def biclass_fn_tpu(X_train, y_train, X_test, y_test, params):\n",
        "  \n",
        "    tf.keras.backend.clear_session()\n",
        "    #dropout = float(params['dropout'])\n",
        "    #dense1_neuron = int(params['dense1_neuron'])\n",
        "    \n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(units=params['dense1_neuron'],input_dim=3,kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(params['activation']))\n",
        "    model.add(tf.keras.layers.Dropout(params['dropout']))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(units=params['dense2_neuron'],kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(params['activation']))\n",
        "    model.add(tf.keras.layers.Dropout(params['dropout']))    \n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(units=params['dense3_neuron'],kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(params['activation']))\n",
        "    model.add(tf.keras.layers.Dropout(params['dropout'])) \n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(units=1,kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(\"sigmoid\"))\n",
        "    \n",
        "    tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "        model,\n",
        "        strategy=tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "        )\n",
        "    )\n",
        "    tpu_model.compile(\n",
        "        optimizer=tf.train.AdamOptimizer(learning_rate=1e-3, ),\n",
        "        loss=tf.keras.losses.binary_crossentropy,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "\n",
        "    out = tpu_model.fit(\n",
        "        X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'],\n",
        "        verbose=0,\n",
        "        validation_data=[X_test, y_test]\n",
        "    )\n",
        "    \n",
        "    return out, tpu_model.sync_to_cpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8niHHAz4A352",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scan_results = ta.Scan(x, y, para, biclass_fn_tpu) #grid_downsample=0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZO63E-UA4fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import talos as ta\n",
        "import os\n",
        "#from talos.model.early_stopper import early_stopper\n",
        "\n",
        "para = {\n",
        "    'dense1_neuron': [2, 3],\n",
        "    'dense2_neuron': [2, 3],\n",
        "    'dense3_neuron': [2, 3],\n",
        "    'activation':['elu', 'selu'], #'tanh' ,'leaky_relu','crelu','selu,','relu6','relu'\n",
        "    'last activation':['sigmoid'], #'softmax'\n",
        "    'dropout': [0],\n",
        "    'batch_size': [32,24],\n",
        "    'weight_regulizer':[None],\n",
        "    'epochs': [450,475,500,525,550,575,600],\n",
        "    'optimizer': ['Adam'],\n",
        "    'kernel_initializer': ['glorot_uniform']\n",
        "}\n",
        "\n",
        "#'hidden_layers':[0, 1, 2, 3]\n",
        "#'first_neuron':[4, 8, 16, 32, 64, 128],\n",
        "\n",
        "\n",
        "def biclass_fn_gpu(X_train, y_train, X_test, y_test, params):\n",
        "  \n",
        "    tf.keras.backend.clear_session()\n",
        "    #dropout = float(params['dropout'])\n",
        "    #dense1_neuron = int(params['dense1_neuron'])\n",
        "    \n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(units=params['dense1_neuron'],input_dim=3,kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(params['activation']))\n",
        "    model.add(tf.keras.layers.Dropout(params['dropout']))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(units=params['dense2_neuron'],kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(params['activation']))\n",
        "    model.add(tf.keras.layers.Dropout(params['dropout']))    \n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(units=params['dense3_neuron'],kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(params['activation']))\n",
        "    model.add(tf.keras.layers.Dropout(params['dropout'])) \n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(units=1,kernel_initializer=\"glorot_uniform\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(params['last activation']))\n",
        "    \n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=tf.train.AdamOptimizer(learning_rate=1e-3, ),\n",
        "        loss=tf.keras.losses.binary_crossentropy,\n",
        "        metrics=['accuracy']) # accuracy\n",
        "\n",
        "\n",
        "    out = model.fit(\n",
        "        X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'],\n",
        "        verbose=0,\n",
        "        validation_data=[X_test, y_test]\n",
        "        #,callbacks=early_stopper(params['epochs'], mode='strict')\n",
        "    ) \n",
        "    \n",
        "    return out, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvrb4S2LA4jQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tf.keras.backend.clear_session()\n",
        "scan_results = ta.Scan(x, y, para, biclass_fn_gpu) #grid_downsample=0.5\n",
        "\n",
        "hkl.dump(scan_results, '/content/drive/My Drive/Colab Notebooks/DrivenData.org/Models_Weights/scan_results_8.hkl', mode='w')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HO7FaPBA4lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scan_results.data.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVSQduf8A4oG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scan_results.data.to_csv('results.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E99WhmP_ejxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# highest val_acc model_id  & index\n",
        "\n",
        "model_id_index = scan_results.data['val_acc'].astype('float').argmax() - 1\n",
        "model_id = model_id_index + 1\n",
        "model_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFu8SaFPiG7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scan_results.details"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za9kMVRQiHH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scan_results.peak_epochs_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYqpORtIBV5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scan_results.peak_epochs_df.to_csv('peak_epochs_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE92XpQNlRGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q hickle\n",
        "import hickle as hkl\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb5bcXj1-zgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqPj4dK4s0Wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hkl.dump(scan_results, 'scan_results_80split.hkl', mode='w')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwptsE_Tils3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save models and weights \n",
        "\n",
        "hkl.dump(scan_results.saved_models, 'models4.hkl', mode='w')\n",
        "#hkl.dump(scan_results.saved_models, 'models_zip.hkl', mode='w', compression='gzip')\n",
        "hkl.dump(scan_results.saved_weights, 'weights4.hkl', mode='w')\n",
        "#hkl.dump(scan_results.saved_models, 'weights_zip.hkl', mode='w', compression='gzip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LjpfpHMlvBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "# Compare filesizes\n",
        "print('Models: %i bytes' % os.path.getsize('models3.hkl'))\n",
        "print('Weights:   %i bytes' % os.path.getsize('weights3.hkl'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwEvjJQap1ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scan_results = hkl.load('/content/drive/My Drive/Colab Notebooks/DrivenData.org/Models_Weights/scan_results_8.hkl') #5nonstratified\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfuHblEhmfGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scan_results.x\n",
        "\n",
        "# Load data from GDrive\n",
        "\n",
        "loaded_models = hkl.load('/content/drive/My Drive/Colab Notebooks/DrivenData.org/Models_Weights/models4.hkl')\n",
        "loaded_weights = hkl.load('/content/drive/My Drive/Colab Notebooks/DrivenData.org/Models_Weights/weights4.hkl')\n",
        "\n",
        "# Check the two are the same file\n",
        "#assert scan_results.saved_models == loaded_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RboDppzn_tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "#model = model_from_json(scan_results.saved_models[126])\n",
        "model = model_from_json(loaded_models[147])\n",
        "\n",
        "#model.set_weights(scan_results.saved_weights[126])\n",
        "model.set_weights(loaded_weights[147])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrbaKVMvn_0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save('./best_model.h5')\n",
        "#from google.colab import files\n",
        "#files.download('./best_model.h5')\n",
        "\n",
        "!pip install -q keras_sequential_ascii\n",
        "from keras_sequential_ascii import keras2ascii\n",
        "keras2ascii(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmf5GYuUs6ZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_features = datatest.iloc[:,1:].values\n",
        "test_features = sc.transform(test_features)\n",
        "test_features[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KiiE5ZHs6hI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predict = model.predict_proba(test_features)\n",
        "df=pd.DataFrame(data=test_predict)\n",
        "df.columns = ['Made Donation in March 2007']\n",
        "df.index = [659,\t276,\t263,\t303,\t83,\t500,\t530,\t244,\t249,\t728,\t129,\t534,\t317,\t401,\t696,\t192,\t176,\t571,\t139,\t423,\t563,\t56,\t528,\t101,\t467,\t382,\t466,\t294,\t512,\t659,\t389,\t487,\t701,\t419,\t536,\t240,\t508,\t515,\t283,\t650,\t65,\t228,\t741,\t297,\t464,\t63,\t231,\t28,\t248,\t357,\t300,\t726,\t680,\t520,\t254,\t582,\t143,\t98,\t1,\t221,\t352,\t64,\t138,\t745,\t64,\t688,\t623,\t289,\t174,\t690,\t105,\t427,\t48,\t14,\t657,\t301,\t455,\t579,\t722,\t98,\t491,\t303,\t466,\t65,\t300,\t9,\t622,\t323,\t289,\t568,\t290,\t156,\t464,\t426,\t306,\t4,\t12,\t187,\t406,\t96,\t509,\t733,\t548,\t478,\t501,\t127,\t199,\t299,\t162,\t235,\t23,\t473,\t487,\t683,\t303,\t309,\t569,\t34,\t686,\t84,\t733,\t537,\t181,\t453,\t67,\t161,\t307,\t703,\t181,\t246,\t316,\t278,\t346,\t545,\t419,\t694,\t622,\t663,\t262,\t461,\t373,\t233,\t466,\t207,\t263,\t16,\t513,\t449,\t429,\t701,\t632,\t529,\t245,\t344,\t353,\t241,\t633,\t624,\t726,\t189,\t138,\t402,\t511,\t590,\t334,\t447,\t119,\t389,\t644,\t423,\t131,\t405,\t82,\t643,\t156,\t617,\t574,\t272,\t613,\t545,\t685,\t570,\t537,\t691,\t85,\t483,\t455,\t93,\t744,\t33,\t321,\t523,\t426,\t196,\t301,\t103,\t224,\t454,\t585,\t154]\n",
        "df.to_csv('Talos3.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waAXCxscs6jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test_predict = model.predict(test_features)\n",
        "#df=pd.DataFrame(data=test_predict)\n",
        "#df.to_csv('Talos3.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzrXoYBBvKTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = pd.read_csv('/content/drive/My Drive/Colab Notebooks/DrivenData.org/correlations.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRwNE12wvcPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr.drop(\"Score\", axis=1).apply(lambda x: x.corr(corr.Score))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}